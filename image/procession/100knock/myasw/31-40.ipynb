{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Affine\n",
    "def affine(img, dx=30, dy=30):\n",
    "    # get shape\n",
    "    H, W, C = img.shape\n",
    "\n",
    "    # Affine hyper parameters\n",
    "    a = 1.\n",
    "    b = dx / H\n",
    "    c = dy / W\n",
    "    d = 1.\n",
    "    tx = 0.\n",
    "    ty = 0.\n",
    "\n",
    "    # prepare temporary\n",
    "    _img = np.zeros((H+2, W+2, C), dtype=np.float32)\n",
    "\n",
    "    # insert image to center of temporary\n",
    "    _img[1:H+1, 1:W+1] = img\n",
    "\n",
    "    # prepare affine image temporary\n",
    "    H_new = np.ceil(dy + H).astype(np.int)\n",
    "    W_new = np.ceil(dx + W).astype(np.int)\n",
    "    out = np.zeros((H_new, W_new, C), dtype=np.float32)\n",
    "\n",
    "    # preprare assigned index\n",
    "    x_new = np.tile(np.arange(W_new), (H_new, 1))\n",
    "    y_new = np.arange(H_new).repeat(W_new).reshape(H_new, -1)\n",
    "\n",
    "    # prepare inverse matrix for affine\n",
    "    adbc = a * d - b * c\n",
    "    x = np.round((d * x_new  - b * y_new) / adbc).astype(np.int) - tx + 1\n",
    "    y = np.round((-c * x_new + a * y_new) / adbc).astype(np.int) - ty + 1\n",
    "\n",
    "    x = np.minimum(np.maximum(x, 0), W+1).astype(np.int)\n",
    "    y = np.minimum(np.maximum(y, 0), H+1).astype(np.int)\n",
    "\n",
    "    # assign value from original to affine image\n",
    "    out[y_new, x_new] = _img[y, x]\n",
    "    out = out.astype(np.uint8)\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "# Read image\n",
    "img = cv2.imread(\"../Question_31_40/imori.jpg\").astype(np.float32)\n",
    "\n",
    "# Affine\n",
    "out = affine(img, dx=30, dy=30)\n",
    "\n",
    "# Save result\n",
    "cv2.imwrite(\"out.jpg\", out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# DFT hyper-parameters\n",
    "K, L = 128, 128\n",
    "channel = 3\n",
    "\n",
    "\n",
    "# DFT\n",
    "def dft(img):\n",
    "\tH, W, _ = img.shape\n",
    "\n",
    "\t# Prepare DFT coefficient\n",
    "\tG = np.zeros((L, K, channel), dtype=np.complex)\n",
    "\n",
    "\t# prepare processed index corresponding to original image positions\n",
    "\tx = np.tile(np.arange(W), (H, 1))\n",
    "\ty = np.arange(H).repeat(W).reshape(H, -1)\n",
    "\n",
    "\t# dft\n",
    "\tfor c in range(channel):\n",
    "\t\tfor l in range(L):\n",
    "\t\t\tfor k in range(K):\n",
    "\t\t\t\tG[l, k, c] = np.sum(img[..., c] * np.exp(-2j * np.pi * (x * k / K + y * l / L))) / np.sqrt(K * L)\n",
    "\t\t\t\t#for n in range(N):\n",
    "\t\t\t\t#    for m in range(M):\n",
    "\t\t\t\t#        v += gray[n, m] * np.exp(-2j * np.pi * (m * k / M + n * l / N))\n",
    "\t\t\t\t#G[l, k] = v / np.sqrt(M * N)\n",
    "\n",
    "\treturn G\n",
    "\n",
    "# IDFT\n",
    "def idft(G):\n",
    "\t# prepare out image\n",
    "\tH, W, _ = G.shape\n",
    "\tout = np.zeros((H, W, channel), dtype=np.float32)\n",
    "\n",
    "\t# prepare processed index corresponding to original image positions\n",
    "\tx = np.tile(np.arange(W), (H, 1))\n",
    "\ty = np.arange(H).repeat(W).reshape(H, -1)\n",
    "\n",
    "\t# idft\n",
    "\tfor c in range(channel):\n",
    "\t\tfor l in range(H):\n",
    "\t\t\tfor k in range(W):\n",
    "\t\t\t\tout[l, k, c] = np.abs(np.sum(G[..., c] * np.exp(2j * np.pi * (x * k / W + y * l / H)))) / np.sqrt(W * H)\n",
    "\n",
    "\t# clipping\n",
    "\tout = np.clip(out, 0, 255)\n",
    "\tout = out.astype(np.uint8)\n",
    "\n",
    "\treturn out\n",
    "\n",
    "\n",
    "\n",
    "# Read image\n",
    "img = cv2.imread(\"../Question_31_40/imori.jpg\").astype(np.float32)\n",
    "\n",
    "# DFT\n",
    "G = dft(img)\n",
    "\n",
    "# write poser spectal to image\n",
    "ps = (np.abs(G) / np.abs(G).max() * 255).astype(np.uint8)\n",
    "cv2.imwrite(\"out_ps.jpg\", ps)\n",
    "\n",
    "# IDFT\n",
    "out = idft(G)\n",
    "\n",
    "# Save result\n",
    "cv2.imwrite(\"out.jpg\", out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# DFT hyper-parameters\n",
    "K, L = 128, 128\n",
    "channel = 3\n",
    "\n",
    "# bgr -> gray\n",
    "def bgr2gray(img):\n",
    "\tgray = 0.2126 * img[..., 2] + 0.7152 * img[..., 1] + 0.0722 * img[..., 0]\n",
    "\treturn gray\n",
    "\n",
    "\n",
    "# DFT\n",
    "def dft(img):\n",
    "\t# Prepare DFT coefficient\n",
    "\tG = np.zeros((L, K, channel), dtype=np.complex)\n",
    "\n",
    "\t# prepare processed index corresponding to original image positions\n",
    "\tx = np.tile(np.arange(W), (H, 1))\n",
    "\ty = np.arange(H).repeat(W).reshape(H, -1)\n",
    "\n",
    "\t# dft\n",
    "\tfor c in range(channel):\n",
    "\t\tfor l in range(L):\n",
    "\t\t\tfor k in range(K):\n",
    "\t\t\t\tG[l, k, c] = np.sum(img[..., c] * np.exp(-2j * np.pi * (x * k / K + y * l / L))) / np.sqrt(K * L)\n",
    "\t\t\t\t#for n in range(N):\n",
    "\t\t\t\t#    for m in range(M):\n",
    "\t\t\t\t#        v += gray[n, m] * np.exp(-2j * np.pi * (m * k / M + n * l / N))\n",
    "\t\t\t\t#G[l, k] = v / np.sqrt(M * N)\n",
    "\n",
    "\treturn G\n",
    "\n",
    "# IDFT\n",
    "def idft(G):\n",
    "\t# prepare out image\n",
    "\tH, W, _ = G.shape\n",
    "\tout = np.zeros((H, W, channel), dtype=np.float32)\n",
    "\n",
    "\t# prepare processed index corresponding to original image positions\n",
    "\tx = np.tile(np.arange(W), (H, 1))\n",
    "\ty = np.arange(H).repeat(W).reshape(H, -1)\n",
    "\n",
    "\t# idft\n",
    "\tfor c in range(channel):\n",
    "\t\tfor l in range(H):\n",
    "\t\t\tfor k in range(W):\n",
    "\t\t\t\tout[l, k, c] = np.abs(np.sum(G[..., c] * np.exp(2j * np.pi * (x * k / W + y * l / H)))) / np.sqrt(W * H)\n",
    "\n",
    "\t# clipping\n",
    "\tout = np.clip(out, 0, 255)\n",
    "\tout = out.astype(np.uint8)\n",
    "\n",
    "\treturn out\n",
    "\n",
    "\n",
    "# HPF\n",
    "def hpf(G, ratio=0.1):\n",
    "\tH, W, _ = G.shape\t\n",
    "\n",
    "\t# transfer positions\n",
    "\t_G = np.zeros_like(G)\n",
    "\t_G[:H//2, :W//2] = G[H//2:, W//2:]\n",
    "\t_G[:H//2, W//2:] = G[H//2:, :W//2]\n",
    "\t_G[H//2:, :W//2] = G[:H//2, W//2:]\n",
    "\t_G[H//2:, W//2:] = G[:H//2, :W//2]\n",
    "\n",
    "\t# get distance from center (H / 2, W / 2)\n",
    "\tx = np.tile(np.arange(W), (H, 1))\n",
    "\ty = np.arange(H).repeat(W).reshape(H, -1)\n",
    "\n",
    "\t# make filter\n",
    "\t_x = x - W // 2\n",
    "\t_y = y - H // 2\n",
    "\tr = np.sqrt(_x ** 2 + _y ** 2)\n",
    "\tmask = np.ones((H, W), dtype=np.float32)\n",
    "\tmask[r < (W // 2 * ratio)] = 0\n",
    "\n",
    "\tmask = np.repeat(mask, channel).reshape(H, W, channel)\n",
    "\n",
    "\t# filtering\n",
    "\t_G *= mask\n",
    "\n",
    "\t# reverse original positions\n",
    "\tG[:H//2, :W//2] = _G[H//2:, W//2:]\n",
    "\tG[:H//2, W//2:] = _G[H//2:, :W//2]\n",
    "\tG[H//2:, :W//2] = _G[:H//2, W//2:]\n",
    "\tG[H//2:, W//2:] = _G[:H//2, :W//2]\n",
    "\n",
    "\treturn G\n",
    "\n",
    "\n",
    "# Read image\n",
    "img = cv2.imread(\"../Question_31_40/imori.jpg\").astype(np.float32)\n",
    "H, W, C = img.shape\n",
    "\n",
    "# Gray scale\n",
    "gray = bgr2gray(img)\n",
    "\n",
    "# DFT\n",
    "G = dft(img)\n",
    "\n",
    "# HPF\n",
    "G = hpf(G)\n",
    "\n",
    "# IDFT\n",
    "out = idft(G)\n",
    "\n",
    "# Save result\n",
    "cv2.imwrite(\"out.jpg\", out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# DFT hyper-parameters\n",
    "K, L = 128, 128\n",
    "channel = 3\n",
    "\n",
    "# bgr -> gray\n",
    "def bgr2gray(img):\n",
    "\tgray = 0.2126 * img[..., 2] + 0.7152 * img[..., 1] + 0.0722 * img[..., 0]\n",
    "\treturn gray\n",
    "\n",
    "\n",
    "# DFT\n",
    "def dft(img):\n",
    "\t# Prepare DFT coefficient\n",
    "\tG = np.zeros((L, K, channel), dtype=np.complex)\n",
    "\n",
    "\t# prepare processed index corresponding to original image positions\n",
    "\tx = np.tile(np.arange(W), (H, 1))\n",
    "\ty = np.arange(H).repeat(W).reshape(H, -1)\n",
    "\n",
    "\t# dft\n",
    "\tfor c in range(channel):\n",
    "\t\tfor l in range(L):\n",
    "\t\t\tfor k in range(K):\n",
    "\t\t\t\tG[l, k, c] = np.sum(img[..., c] * np.exp(-2j * np.pi * (x * k / K + y * l / L))) / np.sqrt(K * L)\n",
    "\t\t\t\t#for n in range(N):\n",
    "\t\t\t\t#    for m in range(M):\n",
    "\t\t\t\t#        v += gray[n, m] * np.exp(-2j * np.pi * (m * k / M + n * l / N))\n",
    "\t\t\t\t#G[l, k] = v / np.sqrt(M * N)\n",
    "\n",
    "\treturn G\n",
    "\n",
    "# IDFT\n",
    "def idft(G):\n",
    "\t# prepare out image\n",
    "\tH, W, _ = G.shape\n",
    "\tout = np.zeros((H, W, channel), dtype=np.float32)\n",
    "\n",
    "\t# prepare processed index corresponding to original image positions\n",
    "\tx = np.tile(np.arange(W), (H, 1))\n",
    "\ty = np.arange(H).repeat(W).reshape(H, -1)\n",
    "\n",
    "\t# idft\n",
    "\tfor c in range(channel):\n",
    "\t\tfor l in range(H):\n",
    "\t\t\tfor k in range(W):\n",
    "\t\t\t\tout[l, k, c] = np.abs(np.sum(G[..., c] * np.exp(2j * np.pi * (x * k / W + y * l / H)))) / np.sqrt(W * H)\n",
    "\n",
    "\t# clipping\n",
    "\tout = np.clip(out, 0, 255)\n",
    "\tout = out.astype(np.uint8)\n",
    "\n",
    "\treturn out\n",
    "\n",
    "\n",
    "# HPF\n",
    "def hpf(G, ratio=0.1):\n",
    "\tH, W, _ = G.shape\t\n",
    "\n",
    "\t# transfer positions\n",
    "\t_G = np.zeros_like(G)\n",
    "\t_G[:H//2, :W//2] = G[H//2:, W//2:]\n",
    "\t_G[:H//2, W//2:] = G[H//2:, :W//2]\n",
    "\t_G[H//2:, :W//2] = G[:H//2, W//2:]\n",
    "\t_G[H//2:, W//2:] = G[:H//2, :W//2]\n",
    "\n",
    "\t# get distance from center (H / 2, W / 2)\n",
    "\tx = np.tile(np.arange(W), (H, 1))\n",
    "\ty = np.arange(H).repeat(W).reshape(H, -1)\n",
    "\n",
    "\t# make filter\n",
    "\t_x = x - W // 2\n",
    "\t_y = y - H // 2\n",
    "\tr = np.sqrt(_x ** 2 + _y ** 2)\n",
    "\tmask = np.ones((H, W), dtype=np.float32)\n",
    "\tmask[r < (W // 2 * ratio)] = 0\n",
    "\n",
    "\tmask = np.repeat(mask, channel).reshape(H, W, channel)\n",
    "\n",
    "\t# filtering\n",
    "\t_G *= mask\n",
    "\n",
    "\t# reverse original positions\n",
    "\tG[:H//2, :W//2] = _G[H//2:, W//2:]\n",
    "\tG[:H//2, W//2:] = _G[H//2:, :W//2]\n",
    "\tG[H//2:, :W//2] = _G[:H//2, W//2:]\n",
    "\tG[H//2:, W//2:] = _G[:H//2, :W//2]\n",
    "\n",
    "\treturn G\n",
    "\n",
    "\n",
    "# Read image\n",
    "img = cv2.imread(\"../Question_31_40/imori.jpg\").astype(np.float32)\n",
    "H, W, C = img.shape\n",
    "\n",
    "# Gray scale\n",
    "gray = bgr2gray(img)\n",
    "\n",
    "# DFT\n",
    "G = dft(img)\n",
    "\n",
    "# HPF\n",
    "G = hpf(G)\n",
    "\n",
    "# IDFT\n",
    "out = idft(G)\n",
    "\n",
    "# Save result\n",
    "cv2.imwrite(\"out.jpg\", out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
